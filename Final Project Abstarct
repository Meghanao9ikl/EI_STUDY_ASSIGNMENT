This project develops a hybrid model that combines XLM-R, a transformer-based model for cross-lingual text processing, with LSTM, a neural network designed to capture sequential patterns in text. XLM-R handles multilingual input with high accuracy, making it effective for processing reviews from various languages, including low-resource ones. The LSTM component enhances sentiment prediction by retaining important information across long sequences, enabling the model to better understand the flow and context of sentences. Together, these models create a powerful system for sentiment analysis, particularly in multilingual social media reviews. This approach significantly improves sentiment classification performance, especially for languages with limited resources. The hybrid model demonstrates the benefits of integrating pre-trained transformers with recurrent networks, making it highly applicable to diverse multilingual datasets and real-world tasks that require robust sentiment analysis across different languages.
